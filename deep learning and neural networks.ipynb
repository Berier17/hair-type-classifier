{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM9Ggn4j6i2xDOwNoC/5thw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"SpUE9pNFGJy9","executionInfo":{"status":"ok","timestamp":1764663654751,"user_tz":-240,"elapsed":23,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","source":["print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"his50eC6GqQu","executionInfo":{"status":"ok","timestamp":1764663656281,"user_tz":-240,"elapsed":18,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"9a4305b4-23e5-41b2-8dfc-e8dfa122603a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.0+cu126\n"]}]},{"cell_type":"code","source":["print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9EpFFZZGwi4","executionInfo":{"status":"ok","timestamp":1764663657498,"user_tz":-240,"elapsed":24,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"38724a11-9453-49a0-d70a-2941b6e91290"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ec5EgNGcHmLW","executionInfo":{"status":"ok","timestamp":1764663658691,"user_tz":-240,"elapsed":18,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"da632dc0-943a-48cc-aec6-4a73ae21772d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n","!unzip -q data.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-MBRLAtH93T","executionInfo":{"status":"ok","timestamp":1764663662809,"user_tz":-240,"elapsed":2631,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"ef92285a-ab27-4a5f-f78f-1ee43f627960"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-12-02 08:20:58--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-02T09%3A13%3A29Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-02T08%3A12%3A41Z&ske=2025-12-02T09%3A13%3A29Z&sks=b&skv=2018-11-09&sig=rhKAJkoYNxP5FHNjEgRl5RY%2BKJoLVI6bTBlVS9nwCIk%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDY2NTQ1OSwibmJmIjoxNzY0NjYzNjU5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._XSCUyHjBe70pXTocaX5PbQ4OKwISU7DefJQT_fS_B4&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n","--2025-12-02 08:20:59--  https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-02T09%3A13%3A29Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-02T08%3A12%3A41Z&ske=2025-12-02T09%3A13%3A29Z&sks=b&skv=2018-11-09&sig=rhKAJkoYNxP5FHNjEgRl5RY%2BKJoLVI6bTBlVS9nwCIk%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDY2NTQ1OSwibmJmIjoxNzY0NjYzNjU5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._XSCUyHjBe70pXTocaX5PbQ4OKwISU7DefJQT_fS_B4&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n","Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 102516572 (98M) [application/octet-stream]\n","Saving to: ‘data.zip’\n","\n","data.zip            100%[===================>]  97.77M  92.7MB/s    in 1.1s    \n","\n","2025-12-02 08:21:00 (92.7 MB/s) - ‘data.zip’ saved [102516572/102516572]\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","SEED = 42\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(SEED)\n","    torch.cuda.manual_seed_all(SEED)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"metadata":{"id":"sSsxiUjOJ7At","executionInfo":{"status":"ok","timestamp":1764663665129,"user_tz":-240,"elapsed":70,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"cy_JxV6ITI1g","executionInfo":{"status":"ok","timestamp":1764663667256,"user_tz":-240,"elapsed":15,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class HairClassifier(nn.Module):\n","    def __init__ (self):\n","      super().__init__()\n","      self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n","\n","      self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","      self.flatten_size = 32 * 99 * 99\n","\n","      self.fc1 = nn.Linear(self.flatten_size, 64)\n","\n","      self.fc2 = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","\n","        x = x.view(-1, self.flatten_size)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","\n","        return x\n","\n","model = HairClassifier().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","\n",""],"metadata":{"id":"vGx-KTxYFiMo","executionInfo":{"status":"ok","timestamp":1764667447093,"user_tz":-240,"elapsed":353,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pQJe7ZfJjtt","executionInfo":{"status":"ok","timestamp":1764667448840,"user_tz":-240,"elapsed":352,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"2f4dee26-b19b-490b-86ee-159601d05bf0"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 20073473\n"]}]},{"cell_type":"code","source":["from torchvision import transforms\n","train_transforms = transforms.Compose([\n","    transforms.Resize((200, 200)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    ) # ImageNet normalization\n","])\n","test_transforms = transforms.Compose([\n","    transforms.Resize((200, 200)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])"],"metadata":{"id":"EjheUsB-Kgzt","executionInfo":{"status":"ok","timestamp":1764667450021,"user_tz":-240,"elapsed":1,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","import torchvision\n","\n","train_dataset = torchvision.datasets.ImageFolder('./data/train', transform=train_transforms)\n","validation_dataset = torchvision.datasets.ImageFolder('./data/test', transform=test_transforms)\n","\n","train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=2)\n","validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False, num_workers=2)\n","\n","print(f\"Train batch: {len(train_dataset)}\")\n","print(f\"Validation batch: {len(validation_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmF7VO0CN-BN","executionInfo":{"status":"ok","timestamp":1764667451841,"user_tz":-240,"elapsed":334,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"f3094fd8-4d42-4cff-9d1d-46809e35d9c4"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Train batch: 800\n","Validation batch: 201\n"]}]},{"cell_type":"code","source":["model = HairClassifier().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","num_epochs = 10\n","history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n","\n","print(\"Starting training...\")\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        labels = labels.float().unsqueeze(1)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","        # Apply sigmoid for accuracy calculation\n","        predicted = (torch.sigmoid(outputs) > 0.5).float()\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    epoch_loss = running_loss / len(train_dataset)\n","    epoch_acc = correct_train / total_train\n","    history['loss'].append(epoch_loss)\n","    history['acc'].append(epoch_acc)\n","\n","    # Validation part (kept for completeness, though Q3 only asks for train acc)\n","    model.eval()\n","    val_running_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for images, labels in validation_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            labels = labels.float().unsqueeze(1)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            predicted = (torch.sigmoid(outputs) > 0.5).float()\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","\n","    val_epoch_loss = val_running_loss / len(validation_dataset)\n","    val_epoch_acc = correct_val / total_val\n","    history['val_loss'].append(val_epoch_loss)\n","    history['val_acc'].append(val_epoch_acc)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Acc: {epoch_acc:.4f}, Val Acc: {val_epoch_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RDCWwZ3R3fq","executionInfo":{"status":"ok","timestamp":1764667531802,"user_tz":-240,"elapsed":78712,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"e8cf15dc-5648-47d8-e5c7-ec1947dcba75"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training...\n","Epoch 1/10, Train Acc: 0.6375, Val Acc: 0.5871\n","Epoch 2/10, Train Acc: 0.6987, Val Acc: 0.6517\n","Epoch 3/10, Train Acc: 0.7462, Val Acc: 0.6617\n","Epoch 4/10, Train Acc: 0.7762, Val Acc: 0.6667\n","Epoch 5/10, Train Acc: 0.8037, Val Acc: 0.6866\n","Epoch 6/10, Train Acc: 0.8225, Val Acc: 0.6716\n","Epoch 7/10, Train Acc: 0.8638, Val Acc: 0.7065\n","Epoch 8/10, Train Acc: 0.9313, Val Acc: 0.7015\n","Epoch 9/10, Train Acc: 0.9413, Val Acc: 0.7363\n","Epoch 10/10, Train Acc: 0.9437, Val Acc: 0.7264\n"]}]},{"cell_type":"code","source":["median_acc = np.median(history['acc'])\n","std_loss = np.std(history['loss'])\n","\n","print(f\"Median Training Accuracy: {median_acc:.2f}\")\n","print(f\"Standard Deviation of Training Loss: {std_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGV_m-W5SPv4","executionInfo":{"status":"ok","timestamp":1764667671871,"user_tz":-240,"elapsed":354,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"0e957cca-be86-42fe-a30b-3e083115d03b"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Median Training Accuracy: 0.81\n","Standard Deviation of Training Loss: 0.1653\n"]}]},{"cell_type":"code","source":["train_transforms_aug = transforms.Compose([\n","    transforms.RandomRotation(50),\n","    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","train_dataset_aug = torchvision.datasets.ImageFolder('./data/train', transform=train_transforms_aug)\n","train_loader_aug = DataLoader(train_dataset_aug, batch_size=20, shuffle=True, num_workers=2)\n"],"metadata":{"id":"eXJajKbqYgE0","executionInfo":{"status":"ok","timestamp":1764668221594,"user_tz":-240,"elapsed":316,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["\n","aug_history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n","\n","print(\"Continuing training with augmentation for 10 epochs...\")\n","\n","for epoch in range(10):\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","\n","    for images, labels in train_loader_aug:\n","        images, labels = images.to(device), labels.to(device)\n","        labels = labels.float().unsqueeze(1)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","        predicted = (torch.sigmoid(outputs) > 0.5).float()\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    epoch_loss = running_loss / len(train_dataset_aug)\n","    epoch_acc = correct_train / total_train\n","    aug_history['loss'].append(epoch_loss)\n","    aug_history['acc'].append(epoch_acc)\n","\n","\n","    model.eval()\n","    val_running_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for images, labels in validation_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            labels = labels.float().unsqueeze(1)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            predicted = (torch.sigmoid(outputs) > 0.5).float()\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","\n","    val_epoch_loss = val_running_loss / len(validation_dataset)\n","    val_epoch_acc = correct_val / total_val\n","    aug_history['val_loss'].append(val_epoch_loss)\n","    aug_history['val_acc'].append(val_epoch_acc)\n","\n","    print(f\"Aug Epoch {epoch+1}/10, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QJTDulKlbCUo","executionInfo":{"status":"ok","timestamp":1764668369683,"user_tz":-240,"elapsed":101760,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"1e5d6d3b-fd21-464a-a0de-f9814926e5b2"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Continuing training with augmentation for 10 epochs...\n","Aug Epoch 1/10, Loss: 0.6215, Acc: 0.6813, Val Loss: 0.6024, Val Acc: 0.6816\n","Aug Epoch 2/10, Loss: 0.5498, Acc: 0.7163, Val Loss: 0.5625, Val Acc: 0.7363\n","Aug Epoch 3/10, Loss: 0.5223, Acc: 0.7163, Val Loss: 0.4996, Val Acc: 0.7363\n","Aug Epoch 4/10, Loss: 0.5153, Acc: 0.7362, Val Loss: 0.5854, Val Acc: 0.7015\n","Aug Epoch 5/10, Loss: 0.5051, Acc: 0.7488, Val Loss: 0.5247, Val Acc: 0.7463\n","Aug Epoch 6/10, Loss: 0.4769, Acc: 0.7725, Val Loss: 0.6508, Val Acc: 0.6318\n","Aug Epoch 7/10, Loss: 0.4864, Acc: 0.7525, Val Loss: 0.5136, Val Acc: 0.7562\n","Aug Epoch 8/10, Loss: 0.4594, Acc: 0.7863, Val Loss: 0.6602, Val Acc: 0.6368\n","Aug Epoch 9/10, Loss: 0.4523, Acc: 0.7775, Val Loss: 0.4714, Val Acc: 0.7761\n","Aug Epoch 10/10, Loss: 0.4377, Acc: 0.7987, Val Loss: 0.5159, Val Acc: 0.7761\n"]}]},{"cell_type":"code","source":["mean_val_loss_aug = np.mean(aug_history['val_loss'])\n","last_5_accuracies = aug_history['val_acc'][5:]\n","mean_acc = np.mean(last_5_accuracies)\n","\n","print(f\"Mean Validation Loss (Augmented): {mean_val_loss_aug:.2f}\")\n","print(f\"Mean Accuracy (Last 5 Epochs): {mean_acc:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VSH1FY79bNti","executionInfo":{"status":"ok","timestamp":1764668550259,"user_tz":-240,"elapsed":314,"user":{"displayName":"Ali Elberier","userId":"11589908389331929498"}},"outputId":"fab4f397-1a98-4598-ea86-fb9ba90550c7"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Validation Loss (Augmented): 0.56\n","Mean Accuracy (Last 5 Epochs): 0.72\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"k4oeSZyzb9w7"},"execution_count":null,"outputs":[]}]}